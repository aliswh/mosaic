{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9286c6",
   "metadata": {},
   "source": [
    "# MOSAIC: Training and Evaluation Demo\n",
    "\n",
    "This notebook demonstrates how to use the MOSAIC framework for training and evaluating models on radiological report classification. We'll be using the MIMIC dataset example and the Mosaic-4B model from Hugging Face.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "1. Created and activated the conda environment:\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "conda activate mosaic\n",
    "```\n",
    "\n",
    "2. Installed the MOSAIC package:\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccadb4e5",
   "metadata": {},
   "source": [
    "Note: If you're running this in a Jupyter notebook, you'll need to restart the kernel after creating the conda environment. You can do this by clicking \"Kernel\" > \"Restart & Run All\" in the menu.\n",
    "\n",
    "## Directory Structure\n",
    "\n",
    "All outputs from this notebook will be organized in a `mosaic_output` directory with the following structure:\n",
    "\n",
    "```\n",
    "mosaic_output/\n",
    "├── checkpoints/    # Training checkpoints\n",
    "├── model/         # Final saved model\n",
    "├── logs/          # Training logs\n",
    "└── results/       # Evaluation results\n",
    "```\n",
    "\n",
    "## Model Information\n",
    "\n",
    "We'll be using the `AliceSch/mosaic-4b` model from Hugging Face Hub, which is specifically designed for medical text classification tasks. The model will be fine-tuned using LoRA (Low-Rank Adaptation) to make training more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939093f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our Python environment and key packages\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b651fd",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Dependencies\n",
    "\n",
    "First, let's set up our Python environment and install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50218d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/tmp/ipykernel_92574/3269608903.py\", line 2, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/home/alice/miniconda3/envs/mosaic/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Import MOSAIC utilities from our installed package\n",
    "from mosaic import ConfigLoader, DatasetLoader\n",
    "from mosaic.core import finetune, evals\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize configuration\n",
    "config_loader = ConfigLoader()\n",
    "dataset_loader = DatasetLoader(config_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory structure\n",
    "output_dir = \"mosaic_output\"\n",
    "checkpoints_dir = os.path.join(output_dir, \"checkpoints\")\n",
    "saved_model_dir = os.path.join(output_dir, \"model\")\n",
    "logs_dir = os.path.join(output_dir, \"logs\")\n",
    "results_dir = os.path.join(output_dir, \"results\")\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [output_dir, checkpoints_dir, saved_model_dir, logs_dir, results_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"Created directory: {dir_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d502297",
   "metadata": {},
   "source": [
    "## 2. Install Required Packages\n",
    "\n",
    "Let's install the required packages from the requirements.txt file. Note that we're using pip install in quiet mode to avoid cluttering the notebook output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages using pip\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    \"torch\",\n",
    "    \"transformers==4.51.3\",\n",
    "    \"datasets==3.5.0\",\n",
    "    \"peft==0.15.1\",\n",
    "    \"accelerate==1.6.0\",\n",
    "    \"bitsandbytes==0.46.0\",\n",
    "    \"wandb==0.19.9\",\n",
    "    \"pygments\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nPackages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13186187",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset\n",
    "\n",
    "We'll now load the MIMIC dataset from the data directory. The dataset is in CSV format and contains radiological reports with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed MIMIC dataset using our DatasetLoader\n",
    "dataset = {\n",
    "    'train': dataset_loader.load_datasets('mimic', split='train'),\n",
    "    'val': dataset_loader.load_datasets('mimic', split='val'),\n",
    "    'test': dataset_loader.load_datasets('mimic', split='test')\n",
    "}\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "print(f\"Train split: {len(dataset['train'])} examples\")\n",
    "print(f\"Validation split: {len(dataset['val'])} examples\")\n",
    "print(f\"Test split: {len(dataset['test'])} examples\")\n",
    "\n",
    "# Display a sample from the training set\n",
    "print(\"\\nSample from training set:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ed4f2",
   "metadata": {},
   "source": [
    "## 4. Initialize Mosaic-4B Model\n",
    "\n",
    "Now we'll initialize the Mosaic-4B model from Hugging Face and configure it for fine-tuning using LoRA (Low-Rank Adaptation) to make the training more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "model_config = config_loader.load_yaml('models')\n",
    "peft_config = config_loader.load_yaml('peft')\n",
    "\n",
    "# Initialize model using the finetune utility\n",
    "model, tokenizer = finetune.model_init(\n",
    "    model_tag=\"AliceSch/mosaic-4b\",\n",
    "    model_config=model_config,\n",
    "    peft_config=peft_config\n",
    ")\n",
    "\n",
    "print(\"Model initialized with configuration:\")\n",
    "print(f\"Model family: {model_config.get('model_family', 'gemma')}\")\n",
    "print(f\"Max sequence length: {model_config.get('max_seq_length', 512)}\")\n",
    "print(f\"LoRA rank: {model_config.get('lora_rank', 16)}\")\n",
    "print(f\"Batch size: {model_config.get('batch_size', 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29323946",
   "metadata": {},
   "source": [
    "## 5. Fine-tune Model\n",
    "\n",
    "We'll now set up the training arguments and start the fine-tuning process. We'll use a small number of epochs for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute_metrics function first\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions.argmax(-1)\n",
    "    labels = eval_pred.label_ids\n",
    "    \n",
    "    # Calculate metrics using sklearn\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Initialize trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=checkpoints_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=logs_dir,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['val'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"Weight decay: {training_args.weight_decay}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStarting training...\")\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bece778",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Now let's evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set using the evals utility\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(dataset['test'])\n",
    "\n",
    "# Print test results\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Get detailed F1 scores using the evals utility\n",
    "predictions = trainer.predict(dataset['test'])\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Calculate detailed F1 scores\n",
    "from sklearn.metrics import classification_report\n",
    "f1_scores = classification_report(labels, preds, target_names=dataset['test'].features['label'].names)\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8b767",
   "metadata": {},
   "source": [
    "## 7. Run Inference Examples\n",
    "\n",
    "Finally, let's demonstrate how to use the fine-tuned model for inference on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model using the finetune utility\n",
    "save_model(model, tokenizer, saved_model_dir, model_config)\n",
    "print(f\"Model saved to {saved_model_dir}\")\n",
    "\n",
    "def predict_report(text):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class = outputs.logits.argmax(-1).item()\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get class name and probability\n",
    "    class_name = dataset['test'].features['label'].names[predicted_class]\n",
    "    probability = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    return class_name, probability\n",
    "\n",
    "# Example reports from test set\n",
    "example_reports = dataset['test'].select(range(3))\n",
    "\n",
    "print(\"Running inference on example reports:\")\n",
    "for example in example_reports:\n",
    "    text = example['text']\n",
    "    true_label = dataset['test'].features['label'].names[example['label']]\n",
    "    \n",
    "    predicted_label, confidence = predict_report(text)\n",
    "    \n",
    "    print(f\"\\nReport text (truncated): {text[:200]}...\")\n",
    "    print(f\"True label: {true_label}\")\n",
    "    print(f\"Predicted label: {predicted_label}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f54a8",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "\n",
    "Clean up the generated files and directories to free up space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clean up the output directory\n",
    "if os.path.exists(\"mosaic_output\"):\n",
    "    shutil.rmtree(\"mosaic_output\")\n",
    "    print(\"Removed mosaic_output directory\")\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Cleared CUDA cache\")\n",
    "\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
